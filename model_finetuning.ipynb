{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "logger = tf.get_logger()\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained and fine-tuned weights\n",
    "For the baseline model, the pretrained weights were taken from tfhub.dev. But the final model will re-use weights obtained by further pre-training the tfhub model on the fine-foods dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_hub = \"https://tfhub.dev/google/small_bert/bert_uncased_L-4_H-512_A-8/1\"\n",
    "baseline_output_dir = \"finetuned_weights/baseline\"\n",
    "model_output_dir = \"finetuned_weights/bert_small\"\n",
    "start_checkpoint_in_task_pretraining = \"finetuned_weights/in_task_pretraining/model.ckpt-12500\"\n",
    "tf.gfile.MakeDirs(model_output_dir)\n",
    "tf.gfile.MakeDirs(baseline_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT + Classifier layer\n",
    "Take the pretrained weights from BERT and add a single classifier layer on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, num_labels):\n",
    "    bert_module = hub.Module(bert_model_hub, trainable=not is_predicting)\n",
    "    bert_inputs = dict(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "    A = tf.get_variable(\"output_weights\", [hidden_size, num_labels], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "    \n",
    "    output_layer = tf.keras.layers.Dropout(rate=0.1)(output_layer, training= not is_predicting)\n",
    "    logits = tf.nn.xw_plus_b(output_layer, A, bias)\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "        return predictions, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is convenient to wrap this model into a tensorflow estimator which automates the training loop for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "    def model_fn(features, labels, mode, params):\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "            predictions, logits = create_model(is_predicting, input_ids, input_mask, segment_ids, num_labels)\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(label_ids, logits, from_logits=True)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "            \n",
    "            # Summaries\n",
    "            tf.summary.scalar(\"cross_entropy_loss\", loss)\n",
    "            accuracy_value, accuracy_op = tf.metrics.accuracy(label_ids, predictions)\n",
    "            with tf.control_dependencies([accuracy_op]):\n",
    "                tf.summary.scalar(\"accuracy\", accuracy_value)            \n",
    "            for o in tf.get_default_graph().get_operations():\n",
    "                if \"PolynomialDecay\" == o.name:\n",
    "                    print(o.name)\n",
    "                    lr = o.values()[0]                    \n",
    "            tf.summary.scalar(\"learning_rate\", lr)\n",
    "            \n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "            else:\n",
    "                # Calculate evaluation metrics. \n",
    "                eval_metrics = {}\n",
    "                eval_metrics[\"accuracy\"] = tf.metrics.accuracy(label_ids, predictions)\n",
    "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            predictions, logits = create_model(is_predicting, input_ids, input_mask, segment_ids, num_labels)\n",
    "            probs = tf.nn.softmax(logits,axis=-1)\n",
    "            predictions = {'probabilities': probs, 'predictions': predictions, 'labels' : label_ids}\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the final model\n",
    "This can conditionally warm-start from a in-task pretraining checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "batch_size = 64\n",
    "max_seq_len = 128\n",
    "learning_rate = 5e-5\n",
    "num_train_steps = 500000//batch_size\n",
    "num_warmup_steps = 0\n",
    "num_labels = 5 # i.e. num_categories\n",
    "\n",
    "# Select whether to warm start from a specific checkpoint, such as a in-task pretraining\n",
    "# checkpoint. Off  by default\n",
    "warm_start_from = tf.estimator.WarmStartSettings(start_checkpoint_in_task_pretraining,\n",
    "                                                 vars_to_warm_start=\".*bert.*\")\n",
    "warm_start_from = None\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(model_dir=model_output_dir, save_summary_steps=10,\n",
    "                                    save_checkpoints_steps=500, keep_checkpoint_max=2)\n",
    "\n",
    "model_fn = model_fn_builder(num_labels, learning_rate=learning_rate, num_train_steps=num_train_steps,\n",
    "                            num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config,\n",
    "                                   params={\"batch_size\": batch_size},\n",
    "                                   warm_start_from=warm_start_from)\n",
    "\n",
    "train_input_fn = bert.run_classifier.file_based_input_fn_builder(\"datasets/training2\", max_seq_len,\n",
    "                                                                 is_training=True, drop_remainder=True)\n",
    "print(f\"Training for {num_train_steps} steps\")\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run (dev) evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_input_fn = bert.run_classifier.file_based_input_fn_builder(\"datasets/dev2\", max_seq_len, is_training=False, drop_remainder=False)\n",
    "estimator.evaluate(input_fn=dev_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_input_fn = bert.run_classifier.file_based_input_fn_builder(\"datasets/test2\", max_seq_len, is_training=False, drop_remainder=False)\n",
    "predictions = list(estimator.predict(input_fn=dev_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for e in predictions:\n",
    "    y_true.append(e[\"predictions\"])\n",
    "    y_pred.append(e[\"labels\"])\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[f\"{i} star review\" for i in range(1,6)])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
